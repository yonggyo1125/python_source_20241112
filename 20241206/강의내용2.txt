k-최근접 이웃 회귀

참고)
	분류(Classification) : 여러중에서 구별 / 2개 중에서 구분 - 이진 분류
	회귀(Regression) : 예측, 모델을 가장 잘 설명할 수 있는 방정식
		예) 1차 y = ax + b  : a - 기울기, 계수, 가중치, b - 절편
			모델을 가장 잘 설명하는 가장 최적의 기울기와 절편

1. 키워드 정리
1) 회귀 : 임의의 수치를 예측하는 문제입니다. 따라서 타깃값도 임의의 수치가 됩니다.
2) k-최근접 이웃 회귀
    - k-최근접 이웃 알고리즘을 사용해 회귀 문제를 풉니다.
    - 가장 가까운 이웃 샘플을 찾고 이 샘플의 타깃값을 평균하여 예측으로 삼습니다.

3) 결정계수(R^2)
대표적인 회귀 문제의 성능 측정 도구입니다.
1에 가까울수록 좋고, 0에 가깝다면 성능이 나쁜 모델입니다.

4) 과대적합
- 모델의 훈련 세트 성능이 테스트 세트 성능보다 훨씬 높을 때 일어납니다.
- 모델이 훈련 세트에 너무 집착해서 데이터에 내재된 거시적인 패턴을 감지하지 못합니다.

5) 과소적합
- 훈련 세트와 테스트 세트의 성능이 모두 동일하게 낮거나 테스트 세트 성능이 오히려 더 높을 때 일어납니다.
- 이런 경우 더 복잡한 모델을 사용해 훈련 세트에 잘 맞는 모델을 만들어야 합니다.

2. k-최근접 이웃 회귀
- 회귀는 클래스 중 하나로 분류하는 것이 아니라 임의의 어떤 숫자를 예측하는 문제입니다.
- 내년도 경제 성장률을 예측하거나 배달이 도착할 시간을 예측하는 것이 회귀 문제입니다.
- 농어의 무게를 예측하는 것도 회귀가 됩니다.
- 회귀는 정해진 클래스가 없고 임의의 수치를 출력합니다.
- 예측하려는 샘플에 가장 가까운 샘플 k개를 선택합니다. 하지만 회귀이기 때문에 이웃한 샘플의 타깃은 어떤 클래스가 아니라 임의의 수치입니다.
- 이웃 샘플의 수치를 사용해 새로운 샘플 X의 타깃을 예측하는 간단한 방법은 이 수치들의 평균을 구하는 것 입니다.
- 이웃한 샘플의 타깃값이 각각 100, 80, 60이고 이를 평균하면 샘플 X의 예측 타깃값은 80이 됩니다.

3. 데이터 준비

numpy 
	reshape(행, 열) : 행, 열 구조의 배열로 변환

4. 결정 계수( R^2 )
R^2 = 1 - (타깃 - 예측)^2의 합 / (타깃 - 평균)^2의 합니다

4. 평균 제곱 오차
5. 과대적합 vs 과소적합