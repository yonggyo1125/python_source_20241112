특성 공학과 규제
1. 키워드 정리
1) 다중 회귀
- 여러 개의 특성을 사용하는 회귀 모델입니다.
- 특성이 많으면 선형 모델은 강력한 성능을 발휘합니다.
- 특성 공학 : 주어진 특성을 조합하여 새로운 특성을 만드는 일련의 작업 과정입니다.
2) 릿지
- 규제가 있는 선형 회귀 모델 중 하나이며 선형 모델의 계수를 작게 만들어 과대적합을 완화시킵니다.
- 릿지는 비교적 효과가 좋아 널리 사용하는 규제 방법입니다.
3) 라쏘
- 또 다른 규제가 있는 선형 회귀 모델입니다.
- 릿지와 달리 계수 값을 아예 0으로 만들 수도 있습니다.

4) 하이퍼파라미터
- 머신러닝 알고리즘이 학습하지 않는 파라미터, 이런 파라미터는 사람이 사전에 지정해야 합니다.
- 릿지와 라쏘의 규제 강도 alpha 파라미터입니다.


2. 다중 회귀
- 여러 개의 특성을 사용한 선형 회귀를 다중 회귀(multiple regression)라고 부릅니다.
- 1개의 특성을 사용했을 때 선형 회귀 모델이 학습하는 것은 직선입니다. 반면 특성이 2개면 선형 회귀는 평면을 학습합니다.
- 특성이 2개면 타깃값과 함께 3차원 공간을 형성하고 선형 회귀 방정식 타깃 = a X 특성1 + b X 특성2 + 절편은 평면이 됩니다.
- 특성이 3개일 경우 3차원 공간 이상을 그리거나 상상하기는 힘듭니다.
- 선형 회귀를 단순한 직선이나 평면으로 생각하여 성능이 무조건 맞다고 오해해서는 안됩니다. 특성이 많은 고차원에서는 선형 회귀가 매우 복잡한 모델을 표현할 수 있습니다.
- 농어의 길이 뿐만 아니라 높이와 두께도 함께 사용합니다. 이와 더불어 3개의 특성을 각각 제곱하여 추가합니다.
- 또한 각 특성을 서로 곱해서 또 다른 특성을 만들겠습니다. 즉 '농어 길이 X 농어 높이'를 새로운 특성으로 만들게 됩니다. 이렇게 기존의 특성을 사용해 사로운 특성을 뽑아내는 작업을 특성 공학(feature engineering)이라고 부릅니다.

3. 데이터 준비
4. 사이킷런의 변환기
- PolynomialFeatures

5. 다중 회귀 모델 훈련하기

6. 규제
- 규제(regularization)는 머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 훼방하는 것을 말합니다.
- 즉, 모델이 훈련 세트에 과대적합되지 않도록 만드는 것입니다. 선형 회귀 모델의 경우 특성에 곱해지는 계수(또는 기울기)의 크기를 작게 만드는 일입니다.
- 특성의 스케일이 정규화되지 않으면 여기에 곱해지는 계수 값도 차이나게 됩니다. 일반적으로 선형 회귀 모델에 규제를 적용할 때 계수 값의 크기가 서로 많이 다르면 공정하게 제어되지 않을 것입니다.
- 규제를 적용하기 전에 먼저 정규화를 해야 합니다. 사이킷런에서 제공하는 StandardScaler 클래스를 사용하면 됩니다. 이 클래스도 변환기의 하나 입니다.
- 릿지는 계수를 제곱한 값을 기준으로 규제를 적용합니다. 라쏘는 계수의 절대값을 기준으로 규제를 적용합니다.
- 일반적으로 릿지를 조금 더 선호합니다.
- 두 알고리즘 모두 계수의 크기를 줄이지만 라쏘는 아예 0으로 만들 수도 있습니다.

1) 릿지
2) 라쏘